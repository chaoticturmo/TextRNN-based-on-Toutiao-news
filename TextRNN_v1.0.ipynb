{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据预处理\n",
    "class Toutiao_News(Dataset):\n",
    "    def __init__(self, file_path, max_len=30):\n",
    "        self.titles = []\n",
    "        self.labels = []\n",
    "        self.catgory = []\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = f.readlines()\n",
    "        \n",
    "        for line in data:\n",
    "            parts = line.strip().split('_!_')\n",
    "            if len(parts) >= 5:\n",
    "                self.labels.append(int(parts[1]))  # 标签字段\n",
    "                self.titles.append(parts[3])       # 标题字段\n",
    "                self.catgory.append(parts[2])\n",
    "        \n",
    "        self.cat_dict = dict(zip(self.catgory,self.labels)) #建立类型到对应编号的字典\n",
    "        \n",
    "        self.build_vocab() #构建词表\n",
    "        \n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(set(self.labels))} #以字典的方式为标签分配索引\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "        \n",
    "    \n",
    "    def build_vocab(self):\n",
    "        all_chars = []\n",
    "        for title in self.titles:\n",
    "            all_chars.extend(list(title))\n",
    "        \n",
    "        char_counts = Counter(all_chars) #进行字符频次统计\n",
    "        \n",
    "        self.vocab = {'<PAD>': 0, '<UNK>': 1} \n",
    "        for char, count in char_counts.most_common(5000):  #选取最高频的5000个字并编号\n",
    "            self.vocab[char] = len(self.vocab)\n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def text_to_tensor(self, text):\n",
    "        \n",
    "        indices = [self.vocab.get(char, 1) for char in list(text)] #将字符串拆成单个字符\n",
    "        \n",
    "        if len(indices) > self.max_len: #若长度大于上界，则截断\n",
    "            indices = indices[:self.max_len]\n",
    "        else:\n",
    "            indices = indices + [0] * (self.max_len - len(indices)) #若长度小于上界，则填充\n",
    "        \n",
    "        return torch.tensor(indices, dtype=torch.long) #转成张量\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.titles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        title = self.titles[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        title_tensor = self.text_to_tensor(title)\n",
    "        label_idx = self.label_to_idx[label]\n",
    "        \n",
    "        return title_tensor, torch.tensor(label_idx, dtype=torch.long) #X，y的访问方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义RNN模型\n",
    "class TextRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers = 1, dropout = 0.5): #n_layers为LSTM的层数\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0) #词向量嵌入，填充索引=0\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, dropout = dropout if n_layers > 1 else 0) #batch_first=True批量优先\n",
    "        #nn.LSTM的输出样式为(output, (hidden, cell))，其中output为所有时间步的隐藏状态，hidden为最后一个时间步的隐藏状态，cell为最后一个时间步的细胞状态\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)  # 函数会获取到[batch_size, seq_len, embed_dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded) #output: [batch_size, seq_len, hidden_dim];hidden: [n_layers, batch_size, hidden_dim]; cell: [n_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        hidden = self.dropout(hidden[-1])  # 取最后一个隐藏层[batch_size, hidden_dim]\n",
    "        \n",
    "        return self.fc(hidden)  # 全连接层[batch_size, output_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 训练函数\n",
    "def train(net, iterator, optimizer, loss, device):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for train_batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 将数据移动到GPU\n",
    "        text, labels = train_batch\n",
    "        text = text.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        predictions = net(text)\n",
    "        \n",
    "        l = loss(predictions, labels)\n",
    "        acc = categorical_accuracy(predictions, labels)\n",
    "        \n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss = epoch_loss + l.item()\n",
    "        epoch_acc = epoch_acc + acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 评估函数\n",
    "def evaluate(net, iterator, loss, device):\n",
    "    net.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for train_batch in iterator:\n",
    "            text, labels = train_batch\n",
    "            text = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            predictions = net(text)\n",
    "            \n",
    "            l = loss(predictions, labels)\n",
    "            acc = categorical_accuracy(predictions, labels)\n",
    "            \n",
    "            epoch_loss = epoch_loss + l.item()\n",
    "            epoch_acc = epoch_acc + acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim=1, keepdim=True) #可用于处理多批量的情况\n",
    "    correct = max_preds.squeeze(1).eq(y) #用squeeze(1)来移除dim1是必要的，否则eq(y)会触发广播机制\n",
    "    return correct.sum() / y.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():     # 保存模型\n",
    "    torch.save({\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'vocab': dataset.vocab,\n",
    "        'label_to_idx': dataset.label_to_idx,\n",
    "        'idx_to_label': dataset.idx_to_label,\n",
    "        'cat_dict': dataset.cat_dict,\n",
    "        'max_len': max_len\n",
    "    }, 'text_rnn.pth')\n",
    "    print(\"模型已保存到 text_rnn.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 主函数\n",
    "\n",
    "# 超参数设置\n",
    "batch_size = 64\n",
    "embed_dim = 300\n",
    "hidden_dim = 128\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "n_epoch = 10\n",
    "lr = 0.001\n",
    "max_len = 50\n",
    "\n",
    "# 数据集划分\n",
    "dataset = Toutiao_News('data/toutiao_cat_data.txt/toutiao_cat_data.txt', max_len)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size)\n",
    "\n",
    "# 定义网络\n",
    "net = TextRNN(\n",
    "    vocab_size = dataset.vocab_size,\n",
    "    embed_dim = embed_dim,\n",
    "    hidden_dim = hidden_dim,\n",
    "    output_dim = len(dataset.label_to_idx),\n",
    "    n_layers = n_layers,\n",
    "    dropout = dropout\n",
    ").to(device)  # 将模型移动到GPU\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    train_loss, train_acc = train(net, train_loader, optimizer, loss, device)\n",
    "    test_loss, test_acc = evaluate(net, test_loader, loss, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'Train Loss: {train_loss:.4f}  Train Acc: {train_acc*100:.4f}%')\n",
    "    print(f'Test Loss: {test_loss:.4f}  Test Acc: {test_acc*100:.4f}%')\n",
    "\n",
    "# 绘制训练曲线\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Acc')\n",
    "plt.plot(test_accs, label='Test Acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
