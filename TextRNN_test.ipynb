{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义RNN模型\n",
    "class TextRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers = 1, dropout = 0.5): #n_layers为LSTM的层数\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0) #词向量嵌入，填充索引=0\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, dropout = dropout if n_layers > 1 else 0) #batch_first=True批量优先\n",
    "        #nn.LSTM的输出样式为(output, (hidden, cell))，其中output为所有时间步的隐藏状态，hidden为最后一个时间步的隐藏状态，cell为最后一个时间步的细胞状态\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)  # 函数会获取到[batch_size, seq_len, embed_dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded) #output: [batch_size, seq_len, hidden_dim];hidden: [n_layers, batch_size, hidden_dim]; cell: [n_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        hidden = self.dropout(hidden[-1])  # 取最后一个隐藏层[batch_size, hidden_dim]\n",
    "        \n",
    "        return self.fc(hidden)  # 全连接层[batch_size, output_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入新闻标题：世俱杯大冷门！大巴黎不敌美洲冠军\n",
      "\n",
      "预测示例:\n",
      "标题: 世俱杯大冷门！大巴黎不敌美洲冠军\n",
      "预测类别: news_sports\t\n",
      "请输入新闻标题：深圳宝安黄田荔枝进入采摘季 预计总产量500吨\n",
      "\n",
      "预测示例:\n",
      "标题: 深圳宝安黄田荔枝进入采摘季 预计总产量500吨\n",
      "预测类别: news_agriculture\t\n",
      "请输入新闻标题：电影《炽热年华》热映 多维看点诠释女性力量勾勒时代群像\n",
      "\n",
      "预测示例:\n",
      "标题: 电影《炽热年华》热映 多维看点诠释女性力量勾勒时代群像\n",
      "预测类别: news_entertainment\t\n",
      "请输入新闻标题：SpaceX星舰爆炸现场震撼，官方回应：人员安全，周边无影响\n",
      "\n",
      "预测示例:\n",
      "标题: SpaceX星舰爆炸现场震撼，官方回应：人员安全，周边无影响\n",
      "预测类别: news_tech\t\n",
      "请输入新闻标题：以色列称已掌控德黑兰领空，伊朗目前的整体损失有多大？\n",
      "\n",
      "预测示例:\n",
      "标题: 以色列称已掌控德黑兰领空，伊朗目前的整体损失有多大？\n",
      "预测类别: news_military\t\n"
     ]
    }
   ],
   "source": [
    "# 示例预测\n",
    "def predict(text, model, vocab, label_to_idx, idx_to_label, max_seq_len, cat_dict,device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 预处理文本\n",
    "        indices = [vocab.get(char, 1) for char in list(text)]\n",
    "        if len(indices) > max_seq_len:\n",
    "            indices = indices[:max_seq_len]\n",
    "        else:\n",
    "            indices = indices + [0] * (max_seq_len - len(indices))\n",
    "\n",
    "        tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # 添加batch维度并移到GPU\n",
    "\n",
    "        # 预测\n",
    "        prediction = model(tensor)\n",
    "\n",
    "        # 获取概率最高的类别\n",
    "        pred_idx = prediction.argmax(1).item()\n",
    "        pred_label = idx_to_label[pred_idx]\n",
    "\n",
    "        # 获取概率\n",
    "        probabilities = torch.softmax(prediction, dim=1).squeeze()\n",
    "        pred_name = next((k for k, v in cat_dict.items() if v == pred_label), None)\n",
    "        return pred_name, probabilities\n",
    "    \n",
    "device = torch.device('cuda')\n",
    "# 超参数设置\n",
    "batch_size = 64\n",
    "embed_dim = 300\n",
    "hidden_dim = 128\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "n_epoch = 10\n",
    "lr = 0.001\n",
    "max_len = 50\n",
    "\n",
    "    \n",
    "\n",
    "net = TextRNN(\n",
    "        vocab_size = 5002,\n",
    "        embed_dim = 300,\n",
    "        hidden_dim = 128,\n",
    "        output_dim = 15,\n",
    "        n_layers = 2,\n",
    "        dropout = 0.5\n",
    "    ).to(device) \n",
    "device = torch.device('cuda')\n",
    "for i in range(5):\n",
    "    # 测试预测\n",
    "    sample_title = input(\"请输入新闻标题：\")\n",
    "\n",
    "    # 加载模型参数\n",
    "    checkpoint = torch.load('text_rnn.pth', map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.eval()\n",
    "\n",
    "    predicted_name, probabilities = predict(\n",
    "        sample_title, \n",
    "        net, \n",
    "        checkpoint['vocab'], \n",
    "        checkpoint['label_to_idx'], \n",
    "        checkpoint['idx_to_label'], \n",
    "        checkpoint['max_len'], \n",
    "        checkpoint['cat_dict'], \n",
    "        device\n",
    "    )\n",
    "    print(f\"\\n预测示例:\")\n",
    "    print(f\"标题: {sample_title}\")\n",
    "    print(f\"预测类别: {predicted_name}\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
